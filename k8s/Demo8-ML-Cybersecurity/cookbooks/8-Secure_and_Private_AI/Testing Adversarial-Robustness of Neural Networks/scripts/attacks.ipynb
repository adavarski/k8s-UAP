{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './../') \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import foolbox \n",
    "from foolbox import attacks as fa\n",
    "\n",
    "# own modules\n",
    "from abs_models import utils as u\n",
    "from abs_models import models as mz\n",
    "from abs_models import attack_utils as au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABS model\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model = mz.get_VAE(n_iter=10)              # ABS, do n_iter=50 for original model \n",
    "# model = mz.get_VAE(binary=True)           # ABS with scaling and binaryzation\n",
    "# model = mz.get_binary_CNN()               # Binary CNN\n",
    "# model = mz.get_CNN()                      # Vanilla CNN\n",
    "# model = mz.get_NearestNeighbor()          # Nearest Neighbor, \"nearest L2 dist to each class\"=logits\n",
    "# model = mz.get_madry()                    # Robust network from Madry et al. in tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is agnostic of pytorch/ tensorflow model --> foolbox model\n",
    "if model.code_base == 'tensorflow':\n",
    "    fmodel = foolbox.models.TensorFlowModel(model.x_input, model.pre_softmax, (0., 1.),\n",
    "                                            channel_axis=3)\n",
    "elif model.code_base == 'pytorch':\n",
    "    model.eval()\n",
    "    fmodel = foolbox.models.PyTorchModel(model,   # return logits in shape (bs, n_classes)\n",
    "                                         bounds=(0., 1.), num_classes=10,\n",
    "                                         device=u.dev())\n",
    "else:\n",
    "    print('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.988\n"
     ]
    }
   ],
   "source": [
    "# test model \n",
    "b, l = u.get_batch(bs=10000)  # returns random batch as np.array\n",
    "pred_label = np.argmax(fmodel.batch_predictions(b), axis=1)\n",
    "print('score', float(np.sum(pred_label == l)) / b.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision based attacks\n",
    "Note that this is only demo code. All experiments were optimized to our compute architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, l = u.get_batch(bs=1)  # returns random batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0135a665f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime 31.859752893447876 seconds\n",
      "pred 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0134e795c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "att = fa.DeepFoolL2Attack(fmodel)\n",
    "metric = foolbox.distances.MSE\n",
    "criterion = foolbox.criteria.Misclassification()\n",
    "\n",
    "plt.imshow(b[0, 0], cmap='gray')\n",
    "plt.title('orig')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Estimate gradients from scores\n",
    "if not model.has_grad: \n",
    "    GE = foolbox.gradient_estimators.CoordinateWiseGradientEstimator(0.1)\n",
    "    fmodel = foolbox.models.ModelWithEstimatedGradients(fmodel, GE)\n",
    "\n",
    "# gernate Adversarial\n",
    "a = foolbox.adversarial.Adversarial(fmodel, criterion, b[0], l[0], distance=metric)\n",
    "att(a)   \n",
    "\n",
    "print('runtime', time.time() - start, 'seconds')\n",
    "print('pred', np.argmax(fmodel.predictions(a.image)))\n",
    "if a.image is not None:   # attack was successful\n",
    "    plt.imshow(a.image[0], cmap='gray')\n",
    "    plt.title('adv')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get Trash Adversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.gradient_estimators import CoordinateWiseGradientEstimator as CWGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a = np.random.random((1, 28, 28)).astype(np.float32)\n",
    "a_helper = torch.tensor(torch.from_numpy(a.copy()), requires_grad=True)\n",
    "fixed_class = 1\n",
    "GE = CWGE(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = torch.optim.SGD([a_helper], lr=1, momentum=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = model.confidence_level    # abs 0.0000031, CNN 1439000, madry 60, 1-NN 0.000000000004\n",
    "logits_scale = model.logit_scale                     # ABS 430, madry 1, CNN 1, 1-NN 5\n",
    "\n",
    "a_orig = a\n",
    "plt.imshow(u.t2n(a[0]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "for i in range(10000):\n",
    "    logits = fmodel.predictions(a)\n",
    "    probs = u.t2n(u.confidence_softmax(logits_scale*torch.from_numpy(logits[None, :]), dim=1, \n",
    "                  const=confidence_level))[0]\n",
    "    pred_class = np.argmax(u.t2n(logits).squeeze())\n",
    "    \n",
    "    if probs[fixed_class]>= 0.9:\n",
    "        break   \n",
    "    grads = GE(fmodel.batch_predictions, a, fixed_class, (0,1))\n",
    "\n",
    "    a = au.update_distal_adv(a, a_helper, grads, opti)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'probs {probs[pred_class]:.3f} class', pred_class)\n",
    "        fig, ax = plt.subplots(1,3, squeeze=False, figsize=(10, 4))\n",
    "        ax[0, 0].imshow(u.t2n(a[0]), cmap='gray')\n",
    "        ax[0, 1].imshow(u.t2n(grads[0]), cmap='gray')\n",
    "        ax[0, 2].imshow(np.sign(grads[0]), cmap='gray')\n",
    "        plt.show()\n",
    "plt.imshow(u.t2n(a[0]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Descent Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for abs\n",
    "att = au.LineSearchAttack(model)   # BinaryLineSearchAttack\n",
    "b, l = u.get_batch(bs=200)\n",
    "\n",
    "advs = att(b, l, n_coarse_steps=50+1, n_ft_steps=2)\n",
    "\n",
    "for adv in advs:\n",
    "    adv['img'] = adv['img'].cpu().numpy()\n",
    "\n",
    "for i, (a_i, b_i) in enumerate(zip(advs, b)):\n",
    "    l2 = np.sqrt(a_i['distance'] * 784)  # convert from MSE\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, squeeze=False)\n",
    "    ax[0, 0].set_title(str(a_i['original_label']))\n",
    "    ax[0, 0].imshow(u.t2n(b_i[0]), cmap='gray')\n",
    "    ax[0, 1].set_title(str(a_i['adversarial_label']))\n",
    "    ax[0, 1].imshow(u.t2n(a_i['img'][0]), cmap='gray')\n",
    "    plt.show()\n",
    "    if i ==10:\n",
    "        break\n",
    "print('mean L2', np.mean([np.sqrt(a_i['distance'] * 784) for a_i in advs]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
