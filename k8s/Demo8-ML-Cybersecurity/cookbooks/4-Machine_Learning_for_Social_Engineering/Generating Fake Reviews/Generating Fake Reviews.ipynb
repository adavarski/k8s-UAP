{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index_dict = {\n",
    "    \"\\n\": 0,\n",
    "    \" \": 1,\n",
    "    \"&\": 2,\n",
    "    \"'\": 3,\n",
    "    \"(\": 4,\n",
    "    \")\": 5,\n",
    "    \"-\": 6,\n",
    "    \".\": 7,\n",
    "    \"/\": 8,\n",
    "    \"0\": 9,\n",
    "    \"1\": 10,\n",
    "    \"2\": 11,\n",
    "    \"3\": 12,\n",
    "    \"5\": 13,\n",
    "    \"A\": 14,\n",
    "    \"B\": 15,\n",
    "    \"D\": 16,\n",
    "    \"E\": 17,\n",
    "    \"F\": 18,\n",
    "    \"I\": 19,\n",
    "    \"J\": 20,\n",
    "    \"K\": 21,\n",
    "    \"L\": 22,\n",
    "    \"M\": 23,\n",
    "    \"N\": 24,\n",
    "    \"O\": 25,\n",
    "    \"S\": 26,\n",
    "    \"T\": 27,\n",
    "    \"U\": 28,\n",
    "    \"W\": 29,\n",
    "    \"X\": 30,\n",
    "    \"a\": 31,\n",
    "    \"b\": 32,\n",
    "    \"c\": 33,\n",
    "    \"d\": 34,\n",
    "    \"e\": 35,\n",
    "    \"f\": 36,\n",
    "    \"g\": 37,\n",
    "    \"h\": 38,\n",
    "    \"i\": 39,\n",
    "    \"j\": 40,\n",
    "    \"k\": 41,\n",
    "    \"l\": 42,\n",
    "    \"m\": 43,\n",
    "    \"n\": 44,\n",
    "    \"o\": 45,\n",
    "    \"p\": 46,\n",
    "    \"q\": 47,\n",
    "    \"r\": 48,\n",
    "    \"s\": 49,\n",
    "    \"t\": 50,\n",
    "    \"u\": 51,\n",
    "    \"v\": 52,\n",
    "    \"w\": 53,\n",
    "    \"x\": 54,\n",
    "    \"y\": 55,\n",
    "}\n",
    "chars_list = list(char_to_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "text = open(\"seed_text.txt\").read()\n",
    "max_length = 40\n",
    "\n",
    "rnn = keras.models.Sequential()\n",
    "rnn.add(\n",
    "    layers.LSTM(1024, input_shape=(max_length, len(chars_list)), return_sequences=True)\n",
    ")\n",
    "rnn.add(layers.LSTM(1024, input_shape=(max_length, len(chars_list))))\n",
    "rnn.add(layers.Dense(len(chars_list), activation=\"softmax\"))\n",
    "rnn.load_weights(\"weights.hdf5\")\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, nesterov=True)\n",
    "rnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sample_next_char(preds):\n",
    "    \"\"\"Samples the subsequent character based on a probability distribution.\"\"\"\n",
    "    return np.random.choice(chars_list, p=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "start_index = np.random.randint(0, len(text) - max_length - 1)\n",
    "generated_text = text[start_index : start_index + max_length]\n",
    "sys.stdout.write(generated_text)\n",
    "sentence_length = 1000\n",
    "for i in range(sentence_length):\n",
    "    vec_so_far = np.zeros((1, max_length, len(chars_list)))\n",
    "for t, char in enumerate(generated_text):\n",
    "    vec_so_far[0, t, char_to_index_dict[char]] = 1.0\n",
    "preds = rnn.predict(vec_so_far)[0]\n",
    "next_char = sample_next_char(preds)\n",
    "generated_text += next_char\n",
    "generated_text = generated_text[1:]\n",
    "sys.stdout.write(next_char)\n",
    "sys.stdout.flush()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
