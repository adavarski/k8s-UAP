{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "\n",
    "directories_with_labels = [\n",
    "    (\"Benign PE Samples\", 0),\n",
    "    (\"Benign PE Samples UPX\", 1),\n",
    "    (\"Benign PE Samples Amber\", 2),\n",
    "]\n",
    "list_of_samples = []\n",
    "labels = []\n",
    "for dataset_path, label in directories_with_labels:\n",
    "    samples = [f for f in listdir(dataset_path)]\n",
    "    for file in samples:\n",
    "        file_path = os.path.join(dataset_path, file)\n",
    "        list_of_samples.append(file_path)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "samples_train, samples_test, labels_train, labels_test = train_test_split(\n",
    "    list_of_samples, labels, test_size=0.3, stratify=labels, random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Reads in the binary sequence of a binary file.\"\"\"\n",
    "    with open(file_path, \"rb\") as binary_file:\n",
    "        data = binary_file.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def byte_sequence_to_Ngrams(byte_sequence, N):\n",
    "    \"\"\"Creates a list of N-grams from a byte sequence.\"\"\"\n",
    "    Ngrams = ngrams(byte_sequence, N)\n",
    "    return list(Ngrams)\n",
    "\n",
    "\n",
    "def extract_Ngram_counts(file, N):\n",
    "    \"\"\"Takes a binary file and outputs the N-grams counts of its binary sequence.\"\"\"\n",
    "    filebyte_sequence = read_file(file)\n",
    "    file_Ngrams = byte_sequence_to_Ngrams(filebyte_sequence, N)\n",
    "    return collections.Counter(file_Ngrams)\n",
    "\n",
    "\n",
    "def featurize_sample(sample, K1_most_frequent_Ngrams_list):\n",
    "    \"\"\"Takes a sample and produces a feature vector.\n",
    "    The features are the counts of the K1 N-grams we've selected.\n",
    "    \"\"\"\n",
    "    K1 = len(K1_most_frequent_Ngrams_list)\n",
    "    feature_vector = K1 * [0]\n",
    "    file_Ngrams = extract_Ngram_counts(sample, N)\n",
    "    for i in range(K1):\n",
    "        feature_vector[i] = file_Ngrams[K1_most_frequent_Ngrams_list[i]]\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "total_Ngram_count = collections.Counter([])\n",
    "for file in samples_train:\n",
    "    total_Ngram_count += extract_Ngram_counts(file, N)\n",
    "K1 = 100\n",
    "K1_most_common_Ngrams = total_Ngram_count.most_common(K1)\n",
    "K1_most_common_Ngrams_list = [x[0] for x in K1_most_common_Ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngram_features_list_train = []\n",
    "y_train = []\n",
    "for i in range(len(samples_train)):\n",
    "    file = samples_train[i]\n",
    "    NGram_features = featurize_sample(file, K1_most_common_Ngrams_list)\n",
    "    Ngram_features_list_train.append(NGram_features)\n",
    "    y_train.append(labels_train[i])\n",
    "X_train = Ngram_features_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngram_features_list_test = []\n",
    "y_test = []\n",
    "for i in range(len(samples_test)):\n",
    "    file = samples_test[i]\n",
    "    NGram_features = featurize_sample(file, K1_most_common_Ngrams_list)\n",
    "    Ngram_features_list_test.append(NGram_features)\n",
    "    y_test.append(labels_test[i])\n",
    "X_test = Ngram_features_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,   1,   0],\n",
       "       [  0,  60,   0],\n",
       "       [  0,   0,  23]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
