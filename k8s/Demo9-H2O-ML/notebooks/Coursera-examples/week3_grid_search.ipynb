{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "# for grid search, also need to import h2o.grid\n",
    "import h2o.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>1 hour 9 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>9 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_megan_p7ovho</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.348 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>3</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>3</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         1 hour 9 mins\n",
       "H2O cluster timezone:       America/Chicago\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.3\n",
       "H2O cluster version age:    9 days\n",
       "H2O cluster name:           H2O_from_python_megan_p7ovho\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.348 Gb\n",
       "H2O cluster total cores:    3\n",
       "H2O cluster allowed cores:  3\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data = h2o.import_file('http://h2o-public-test-data.s3.amazonaws.com/smalldata/airlines/allyears2k_headers.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43978"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = data.split_frame([0.8, 0.1], seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35255/4272/4451\n"
     ]
    }
   ],
   "source": [
    "print('%d/%d/%d' % (train.nrows, valid.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'IsArrDelayed'\n",
    "# don't use fields that we know wouldn't be available at prediction time\n",
    "ignore_fields = ['ArrDelay', 'DepDelay', 'CarrierDelay', 'WeatherDelay',\n",
    "                 'NASDelay', 'SecurityDelay', 'LateAircraftDelay',\n",
    "                 'IsDepDelayed', 'IsArrDelayed', 'ActualElapsedTime']\n",
    "# create two x's, one for all but ignored and one for the likely good predictors\n",
    "x_all = [i for i in train.names if i not in ignore_fields]\n",
    "x_likely = ['Month', 'DayOfWeek', 'UniqueCarrier', 'Origin',\n",
    "            'Dest', 'Distance', 'Cancelled', 'Diverted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# create default model with x_all\n",
    "m_def = H2OGeneralizedLinearEstimator(family='binomial')\n",
    "m_def.train(x_all, y, train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6230175599834998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get value of logloss for this model on validation data\n",
    "m_def.logloss(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# set up the grid search using lambda search, search over params for alpha\n",
    "# build max of 8 models and run for max of 30 seconds\n",
    "# use random discrete (instead of cartesian) search\n",
    "g = h2o.grid.H2OGridSearch(\n",
    "    H2OGeneralizedLinearEstimator(\n",
    "        family='binomial',\n",
    "        lambda_search=True\n",
    "    ),\n",
    "    hyper_params={\n",
    "        'alpha': [x * 0.01 for x in range(0, 100)]\n",
    "    },\n",
    "    search_criteria={\n",
    "        'strategy': 'RandomDiscrete',\n",
    "        'max_models': 8,\n",
    "        'max_runtime_secs': 30\n",
    "    }\n",
    ")\n",
    "g.train(x_all, y, train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    alpha  \\\n",
      "0                  [0.96]   \n",
      "1                  [0.84]   \n",
      "2    [0.8200000000000001]   \n",
      "3                  [0.79]   \n",
      "4                   [0.6]   \n",
      "5                  [0.51]   \n",
      "6                  [0.08]   \n",
      "7                  [0.03]   \n",
      "\n",
      "                                                      model_ids  \\\n",
      "0  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_4   \n",
      "1  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_7   \n",
      "2  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_1   \n",
      "3  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_5   \n",
      "4  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_6   \n",
      "5  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_2   \n",
      "6  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_8   \n",
      "7  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_41_model_3   \n",
      "\n",
      "              logloss  \n",
      "0  0.5902640428683208  \n",
      "1   0.591548596791795  \n",
      "2  0.5917254167886266  \n",
      "3  0.5919977408143924  \n",
      "4  0.5940107404940759  \n",
      "5  0.5952204925857723  \n",
      "6  0.6100212141323867  \n",
      "7  0.6192577173020201  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# cartesian version - note that you could leave search_criteria off as this is the H2O default\n",
    "# as this will run for all alphas, scale this back to a smaller number of possible params\n",
    "g2 = h2o.grid.H2OGridSearch(\n",
    "    H2OGeneralizedLinearEstimator(\n",
    "        family='binomial',\n",
    "        lambda_search=True\n",
    "    ),\n",
    "    hyper_params={\n",
    "        'alpha': [0, 0.2, 0.4, 0.5, 0.6, 0.8, 0.99]\n",
    "    },\n",
    "    search_criteria={\n",
    "        'strategy': 'Cartesian'\n",
    "    }\n",
    ")\n",
    "# note trying this with x_likely instead of x_all\n",
    "g2.train(x_likely, y, train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      alpha                                                     model_ids  \\\n",
      "0     [0.4]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_3   \n",
      "1     [0.5]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_4   \n",
      "2     [0.2]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_2   \n",
      "3     [0.6]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_5   \n",
      "4    [0.99]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_7   \n",
      "5     [0.0]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_1   \n",
      "6     [0.8]  Grid_GLM_py_3_sid_b1d5_model_python_1581805811022_58_model_6   \n",
      "\n",
      "              logloss  \n",
      "0  0.6487155628828557  \n",
      "1  0.6487174438261994  \n",
      "2  0.6487198598346858  \n",
      "3  0.6487283432868978  \n",
      "4  0.6487570996218839  \n",
      "5  0.6487590917289415  \n",
      "6  0.6487697515569714  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the logloss is higher across the board when we reduce the features down from x_all to x_likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h2oclass",
   "language": "python",
   "name": "h2oclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
